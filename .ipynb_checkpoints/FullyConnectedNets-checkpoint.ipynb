{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Neural Nets\n",
    "In the previous homework you implemented a fully-connected two-layer neural network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as we move to bigger models. Ideally we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures.\n",
    "\n",
    "In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures.\n",
    "\n",
    "In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch Normalization as a tool to more efficiently optimize deep networks.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train: ', (49000, 3, 32, 32))\n",
      "('y_train: ', (49000,))\n",
      "('X_val: ', (1000, 3, 32, 32))\n",
      "('y_val: ', (1000,))\n",
      "('X_test: ', (1000, 3, 32, 32))\n",
      "('y_test: ', (1000,))\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "  print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: foward\n",
    "Open the file `cs231n/layers.py` and implement the `affine_forward` function.\n",
    "\n",
    "Once you are done you can test your implementaion by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.76984772881e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: backward\n",
    "Now implement the `affine_backward` function and test your implementation using numeric gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  5.39910036865e-11\n",
      "dw error:  9.9042118654e-11\n",
      "db error:  2.41228675681e-11\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "np.random.seed(231)\n",
    "\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: forward\n",
    "Implement the forward pass for the ReLU activation function in the `relu_forward` function and test your implementation using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.99999979802e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 5e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: backward\n",
    "Now implement the backward pass for the ReLU activation function in the `relu_backward` function and test your implementation using numeric gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.27563491363e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be around 3e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sandwich\" layers\n",
    "There are some common patterns of layers that are frequently used in neural nets. For example, affine layers are frequently followed by a ReLU nonlinearity. To make these common patterns easy, we define several convenience layers in the file `cs231n/layer_utils.py`.\n",
    "\n",
    "For now take a look at the `affine_relu_forward` and `affine_relu_backward` functions, and run the following to numerically gradient check the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward:\n",
      "dx error:  6.7505621216e-11\n",
      "dw error:  8.16201557044e-11\n",
      "db error:  7.82672402146e-12\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "print('Testing affine_relu_forward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss layers: Softmax and SVM\n",
    "You implemented these loss functions in the last assignment, so we'll give them to you for free here. You should still make sure you understand how they work by looking at the implementations in `cs231n/layers.py`.\n",
    "\n",
    "You can make sure that the implementations are correct by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.9996027491\n",
      "dx error:  1.40215660067e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.3025458445\n",
      "dx error:  9.38467316199e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
    "print('Testing svm_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer network\n",
    "In the previous assignment you implemented a two-layer neural network in a single monolithic class. Now that you have implemented modular versions of the necessary layers, you will reimplement the two layer network using these modular implementations.\n",
    "\n",
    "Open the file `cs231n/classifiers/fc_net.py` and complete the implementation of the `TwoLayerNet` class. This class will serve as a model for the other networks you will implement in this assignment, so read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "Testing training loss (no regularization)\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.22e-08\n",
      "W2 relative error: 3.48e-10\n",
      "b1 relative error: 6.55e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 8.18e-07\n",
      "W2 relative error: 2.85e-08\n",
      "b1 relative error: 1.09e-09\n",
      "b2 relative error: 7.76e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print('Testing training loss (no regularization)')\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "\n",
    "for reg in [0.0, 0.7]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "In the previous assignment, the logic for training models was coupled to the models themselves. Following a more modular design, for this assignment we have split the logic for training models into a separate class.\n",
    "\n",
    "Open the file `cs231n/solver.py` and read through it to familiarize yourself with the API. After doing so, use a `Solver` instance to train a `TwoLayerNet` that achieves at least `50%` accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 2450) loss: 2.458848\n",
      "(Epoch 0 / 10) train acc: 0.151000; val_acc: 0.139000\n",
      "(Iteration 101 / 2450) loss: 1.901662\n",
      "(Iteration 201 / 2450) loss: 1.908357\n",
      "(Epoch 1 / 10) train acc: 0.439000; val_acc: 0.439000\n",
      "(Iteration 301 / 2450) loss: 1.708966\n",
      "(Iteration 401 / 2450) loss: 1.659031\n",
      "(Epoch 2 / 10) train acc: 0.474000; val_acc: 0.454000\n",
      "(Iteration 501 / 2450) loss: 1.533238\n",
      "(Iteration 601 / 2450) loss: 1.745083\n",
      "(Iteration 701 / 2450) loss: 1.589053\n",
      "(Epoch 3 / 10) train acc: 0.493000; val_acc: 0.465000\n",
      "(Iteration 801 / 2450) loss: 1.648464\n",
      "(Iteration 901 / 2450) loss: 1.498114\n",
      "(Epoch 4 / 10) train acc: 0.533000; val_acc: 0.495000\n",
      "(Iteration 1001 / 2450) loss: 1.363680\n",
      "(Iteration 1101 / 2450) loss: 1.468852\n",
      "(Iteration 1201 / 2450) loss: 1.498593\n",
      "(Epoch 5 / 10) train acc: 0.551000; val_acc: 0.506000\n",
      "(Iteration 1301 / 2450) loss: 1.426673\n",
      "(Iteration 1401 / 2450) loss: 1.423429\n",
      "(Epoch 6 / 10) train acc: 0.565000; val_acc: 0.501000\n",
      "(Iteration 1501 / 2450) loss: 1.456342\n",
      "(Iteration 1601 / 2450) loss: 1.335542\n",
      "(Iteration 1701 / 2450) loss: 1.336815\n",
      "(Epoch 7 / 10) train acc: 0.548000; val_acc: 0.535000\n",
      "(Iteration 1801 / 2450) loss: 1.371454\n",
      "(Iteration 1901 / 2450) loss: 1.359260\n",
      "(Epoch 8 / 10) train acc: 0.585000; val_acc: 0.548000\n",
      "(Iteration 2001 / 2450) loss: 1.383246\n",
      "(Iteration 2101 / 2450) loss: 1.385674\n",
      "(Iteration 2201 / 2450) loss: 1.403177\n",
      "(Epoch 9 / 10) train acc: 0.617000; val_acc: 0.518000\n",
      "(Iteration 2301 / 2450) loss: 1.525209\n",
      "(Iteration 2401 / 2450) loss: 1.445479\n",
      "(Epoch 10 / 10) train acc: 0.606000; val_acc: 0.519000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet()\n",
    "solver = None\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "model = TwoLayerNet(hidden_dim = 200,reg = 0.5)\n",
    "solver = Solver(model, data,\n",
    "                  update_rule='sgd',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                  },\n",
    "                  lr_decay=0.9,\n",
    "                  num_epochs=10, batch_size=200,\n",
    "                  print_every=100)\n",
    "solver.train()\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAALJCAYAAAAnCMuGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05bc8cdcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer network\n",
    "Next you will implement a fully-connected network with an arbitrary number of hidden layers.\n",
    "\n",
    "Read through the `FullyConnectedNet` class in the file `cs231n/classifiers/fc_net.py`.\n",
    "\n",
    "Implement the initialization, the forward pass, and the backward pass. For the moment don't worry about implementing dropout or batch normalization; we will add those features soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial loss and gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, run the following to check the initial loss and to gradient check the network both with and without regularization. Do the initial losses seem reasonable?\n",
    "\n",
    "For gradient checking, you should expect to see errors around 1e-6 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Running check with reg =  0\n",
      "hi there\n",
      "[15, 20, 30, 10]\n",
      "Initial loss:  0.0\n",
      "Running check with reg =  3.14\n",
      "hi there\n",
      "[15, 20, 30, 10]\n",
      "Initial loss:  0.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another sanity check, make sure you can overfit a small dataset of 50 images. First we will try a three-layer network with 100 units in each hidden layer. You will need to tweak the learning rate and initialization scale, but you should be able to overfit and achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3072, 100, 100, 10]\n",
      "(Iteration 1 / 40) loss: 0.000000\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/StanfordGood/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-fa909c059b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 }\n\u001b[1;32m     21\u001b[0m          )\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/assignment2/cs231n/solver.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_it\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlast_it\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 train_acc = self.check_accuracy(self.X_train, self.y_train,\n\u001b[0;32m--> 287\u001b[0;31m                     num_samples=self.num_train_samples)\n\u001b[0m\u001b[1;32m    288\u001b[0m                 val_acc = self.check_accuracy(self.X_val, self.y_val,\n\u001b[1;32m    289\u001b[0m                     num_samples=self.num_val_samples)\n",
      "\u001b[0;32m~/Documentos/assignment2/cs231n/solver.py\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(self, X, y, num_samples, batch_size)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/StanfordGood/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/StanfordGood/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/StanfordGood/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2\n",
    "learning_rate = 1e-4\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to use a five-layer network with 100 units on each layer to overfit 50 training examples. Again you will have to adjust the learning rate and weight initialization, but you should be able to achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_scale = 1e-5\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inline question: \n",
    "Did you notice anything about the comparative difficulty of training the three-layer net vs training the five layer net?\n",
    "\n",
    "# Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "So far we have used vanilla stochastic gradient descent (SGD) as our update rule. More sophisticated update rules can make it easier to train deep networks. We will implement a few of the most commonly used update rules and compare them to vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD+Momentum\n",
    "Stochastic gradient descent with momentum is a widely used update rule that tends to make deep networks converge faster than vanilla stochstic gradient descent.\n",
    "\n",
    "Open the file `cs231n/optim.py` and read the documentation at the top of the file to make sure you understand the API. Implement the SGD+momentum update rule in the function `sgd_momentum` and run the following to check your implementation. You should see errors less than 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done so, run the following to train a six-layer network with both SGD and SGD+momentum. You should see the SGD+momentum update rule converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-2,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp and Adam\n",
    "RMSProp [1] and Adam [2] are update rules that set per-parameter learning rates by using a running average of the second moments of gradients.\n",
    "\n",
    "In the file `cs231n/optim.py`, implement the RMSProp update rule in the `rmsprop` function and implement the Adam update rule in the `adam` function, and check your implementations using the tests below.\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "from cs231n.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "from cs231n.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have debugged your RMSProp and Adam implementations, run the following to train a pair of deep networks using these new update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a good model!\n",
    "Train the best fully-connected model that you can on CIFAR-10, storing your best model in the `best_model` variable. We require you to get at least 50% accuracy on the validation set using a fully-connected net.\n",
    "\n",
    "If you are careful it should be possible to get accuracies above 55%, but we don't require it for this part and won't assign extra credit for doing so. Later in the assignment we will ask you to train the best convolutional network that you can on CIFAR-10, and we would prefer that you spend your effort working on convolutional nets rather than fully-connected nets.\n",
    "\n",
    "You might find it useful to complete the `BatchNormalization.ipynb` and `Dropout.ipynb` notebooks before completing this part, since those techniques can help you train powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# batch normalization and dropout useful. Store your best model in the         #\n",
    "# best_model variable.                                                         #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test you model\n",
    "Run your best model on the validation and test sets. You should achieve above 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
